# R2: Complete Automation Pipeline Guide

## ðŸš€ Quick Start - One Command!

Run the complete research pipeline (validation â†’ experiments â†’ analysis â†’ visualization â†’ report):

```bash
bash run_all.sh
```

That's it! This single command will:
1. âœ… Validate environment and run tests
2. ðŸ“Š Generate synthetic data automatically
3. ðŸ”¬ Run all perturbation experiments (5 scenarios Ã— multiple levels)
4. ðŸ“ˆ Generate visualizations (PNG plots + HTML dashboards)
5. ðŸ“ Create comprehensive final research report with discussion

**Total time:** ~5-15 minutes (depending on `--runs` parameter)

---

## ðŸ“‹ What Gets Automated?

### Complete Pipeline Stages

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   R2 AUTOMATION PIPELINE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. VALIDATION                                                  â”‚
â”‚     â€¢ Python version check                                      â”‚
â”‚     â€¢ Dependencies verification                                 â”‚
â”‚     â€¢ Schema & attribution tests                                â”‚
â”‚                                                                 â”‚
â”‚  2. DATA GENERATION (Automatic - Synthetic)                     â”‚
â”‚     â€¢ 2D "Lift" task environment                                â”‚
â”‚     â€¢ Deterministic seeds for reproducibility                   â”‚
â”‚     â€¢ No manual data downloading needed                         â”‚
â”‚                                                                 â”‚
â”‚  3. EXPERIMENTATION                                             â”‚
â”‚     â€¢ Occlusion sweep       [0.0, 0.2, 0.4, 0.6]               â”‚
â”‚     â€¢ Lighting sweep        [0.0, 0.3, 0.6]                    â”‚
â”‚     â€¢ Motion blur sweep     [0.0, 0.5, 1.0]                    â”‚
â”‚     â€¢ Camera jitter sweep   [0.0, 0.3, 0.6]                    â”‚
â”‚     â€¢ Overlap sweep         [0.0, 0.5]                         â”‚
â”‚                                                                 â”‚
â”‚  4. ANALYSIS                                                    â”‚
â”‚     â€¢ Per-run attribution (rule-based)                          â”‚
â”‚     â€¢ Module failure tracking                                   â”‚
â”‚     â€¢ Root cause identification                                 â”‚
â”‚     â€¢ Cross-scenario comparison                                 â”‚
â”‚                                                                 â”‚
â”‚  5. VISUALIZATION                                               â”‚
â”‚     â€¢ Stacked bar charts (module failures)                      â”‚
â”‚     â€¢ Sensitivity curves (degradation vs perturbation)          â”‚
â”‚     â€¢ Sankey diagrams (failure flow)                            â”‚
â”‚     â€¢ Interactive HTML dashboards                               â”‚
â”‚                                                                 â”‚
â”‚  6. FINAL REPORT                                                â”‚
â”‚     â€¢ Executive summary                                         â”‚
â”‚     â€¢ Key findings                                              â”‚
â”‚     â€¢ Discussion & interpretation                               â”‚
â”‚     â€¢ Recommendations                                           â”‚
â”‚     â€¢ Future work                                               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ Usage

### Basic Usage (Default Settings)

```bash
bash run_all.sh
```

**Defaults:**
- Runs per level: 3
- Results directory: `results/`

### Custom Configuration

```bash
# More runs for statistical significance
bash run_all.sh 10

# Custom results directory
bash run_all.sh 3 my_experiment_results

# Advanced: Python script directly with all options
python scripts/run_all.py \
    --runs 5 \
    --results_dir custom_results \
    --cfg configs/robosuite_grasp.yaml \
    --thresholds configs/thresholds.yaml \
    --perturbations configs/perturbations.yaml
```

### Skip Validation (Faster, Not Recommended)

```bash
python scripts/run_all.py --skip_validation
```

---

## ðŸ“Š Output Structure

After running `bash run_all.sh`, you'll get:

```
results/
â”œâ”€â”€ final_report/
â”‚   â””â”€â”€ research_report.html          â† START HERE! Comprehensive analysis
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ occlusion/
â”‚   â”‚   â”œâ”€â”€ dashboard.html             â† Interactive Plotly dashboard
â”‚   â”‚   â”œâ”€â”€ stacked.png                â† Module failure distribution
â”‚   â”‚   â”œâ”€â”€ sensitivity.png            â† Performance degradation curve
â”‚   â”‚   â””â”€â”€ sankey.png                 â† Failure flow diagram
â”‚   â”œâ”€â”€ lighting/
â”‚   â”‚   â””â”€â”€ [same structure]
â”‚   â”œâ”€â”€ motion_blur/
â”‚   â”‚   â””â”€â”€ [same structure]
â”‚   â”œâ”€â”€ camera_jitter/
â”‚   â”‚   â””â”€â”€ [same structure]
â”‚   â””â”€â”€ overlap/
â”‚       â””â”€â”€ [same structure]
â”‚
â”œâ”€â”€ occlusion_sweep.csv                â† Raw data
â”œâ”€â”€ lighting_sweep.csv
â”œâ”€â”€ motion_blur_sweep.csv
â”œâ”€â”€ camera_jitter_sweep.csv
â”œâ”€â”€ overlap_sweep.csv
â”‚
â”œâ”€â”€ logs/                              â† JSONL logs per run
â”‚   â””â”€â”€ [individual .jsonl files]
â”‚
â””â”€â”€ artifacts/                         â† Images, masks, path plots
    â””â”€â”€ [RGB, masks, path visualizations]
```

---

## ðŸ” Understanding the Results

### 1. Final Research Report (START HERE!)

Open in browser:
```bash
# Linux/Mac
open results/final_report/research_report.html

# Or manually navigate to:
file:///path/to/xai/results/final_report/research_report.html
```

**Contents:**
- **Executive Summary**: Overall statistics
- **Key Findings**: Top insights (success rates, module vulnerabilities, root causes, sensitivity)
- **Detailed Results**: Per-scenario breakdowns with tables
- **Discussion**: Interpretation, methodology, limitations
- **Recommendations**: Actionable next steps
- **Future Work**: Research directions

### 2. Interactive Dashboards

Each scenario has an interactive Plotly dashboard:
```bash
open results/reports/occlusion/dashboard.html
```

Explore:
- Hover over charts for details
- Filter data dynamically
- Zoom into specific perturbation levels

### 3. PNG Visualizations

Three types of plots per scenario:

1. **Stacked Bar Chart** (`stacked.png`)
   - Shows which modules fail at each perturbation level
   - Color-coded by module (Vision, Geometry, Planning, Control)

2. **Sensitivity Curve** (`sensitivity.png`)
   - X-axis: Perturbation level
   - Y-axis: Success rate
   - Shows performance degradation

3. **Sankey Diagram** (`sankey.png`)
   - Flow from perturbation â†’ module failures â†’ root causes
   - Width indicates frequency

### 4. Raw Data (CSV)

For custom analysis:
```python
import pandas as pd
df = pd.read_csv("results/occlusion_sweep.csv")
print(df.head())
```

**Columns:**
- Metadata: `run_id`, `scenario`, `level`, `seed`
- Perception: `perception.avg_conf`, `perception.detected`, `perception.seg_iou`
- Geometry: `geometry.pnp_success`, `geometry.pnp_rmse`
- Planning: `planning.success`, `planning.path_cost`, `planning.collisions`
- Control: `control.track_rmse`, `control.overshoot`, `control.oscillation`
- System: `system.success`, `system.final_dist_to_goal`
- Attribution: `attr_modules`, `attr_errors`, `root_cause`

---

## âš™ï¸ Configuration

### Modify Perturbation Scenarios

Edit `configs/perturbations.yaml`:

```yaml
scenarios:
  - name: "occlusion"
    levels: [0.0, 0.2, 0.4, 0.6, 0.8]  # Add more levels
  - name: "lighting"
    levels: [0.0, 0.3, 0.6, 0.9]       # Increase range
  # Add new scenarios...
```

### Adjust Success Thresholds

Edit `configs/thresholds.yaml`:

```yaml
perception:
  min_confidence: 0.5      # Detection confidence threshold
  min_seg_iou: 0.6         # Segmentation quality threshold

geometry:
  max_pnp_rmse: 2.0        # Pose estimation error threshold

planning:
  max_collisions: 0        # Zero tolerance for collisions
  max_path_cost_ratio: 2.0

control:
  max_track_rmse: 0.05     # Tracking accuracy threshold
  max_overshoot: 0.1

system:
  max_final_distance: 0.05  # Success criterion: within 5cm
```

### Change Task Configuration

Edit `configs/robosuite_grasp.yaml`:

```yaml
task: "Lift"
robot: "Panda"
camera:
  resolution: [640, 480]  # Increase resolution
  fov: 60

simulation:
  max_steps: 150          # Longer episodes
  seeds: [0, 1, 2, 3, 4]  # More seeds for diversity
```

---

## ðŸ§ª Running Individual Components

### Run Tests Only

```bash
python -m tests.test_schemas
python -m tests.test_attribution
```

### Run Single Scenario

```bash
python scripts/sweep_perturb.py \
    --cfg configs/robosuite_grasp.yaml \
    --scenario occlusion \
    --levels 0.0 0.2 0.4 0.6 \
    --thresholds configs/thresholds.yaml \
    --runs 3 \
    --merge_csv results/occlusion_only.csv
```

### Generate Report from Existing Data

```bash
python scripts/export_report.py \
    --csv results/occlusion_sweep.csv \
    --out results/reports/occlusion \
    --thresholds configs/thresholds.yaml
```

### Generate Final Report from Multiple CSVs

```bash
python scripts/generate_final_report.py \
    --csv results/occlusion_sweep.csv \
    --csv results/lighting_sweep.csv \
    --csv results/motion_blur_sweep.csv \
    --results_dir results/reports \
    --output_dir results/final_report
```

---

## ðŸ”¬ Extending the Pipeline

### Add New Perturbation Type

1. Create perturbation module:
   ```python
   # perturb/my_perturbation.py
   def apply_my_perturbation(img, level):
       # Your perturbation logic
       return perturbed_img
   ```

2. Register in `configs/perturbations.yaml`:
   ```yaml
   scenarios:
     - name: "my_perturbation"
       levels: [0.0, 0.5, 1.0]
   ```

3. Run pipeline:
   ```bash
   bash run_all.sh
   ```

### Replace Stub Modules with Real Implementations

**Example: Replace detector stub with YOLO**

1. Install YOLO:
   ```bash
   pip install ultralytics
   ```

2. Modify `vision/detector_stub.py`:
   ```python
   from ultralytics import YOLO

   def detect(img):
       model = YOLO('yolov8n.pt')
       results = model(img)
       # Convert to R2 format
       return {
           "detected": len(results) > 0,
           "avg_conf": results[0].boxes.conf.mean(),
           "bbox": results[0].boxes.xyxy[0],
       }
   ```

3. Pipeline automatically uses new detector:
   ```bash
   bash run_all.sh
   ```

---

## ðŸ“ˆ Interpreting Key Metrics

### Success Rate
- **100%**: Perfect robustness (no failures at any perturbation level)
- **50-100%**: Degraded but functional
- **0-50%**: Severe impact
- **0%**: Complete failure

### Sensitivity Slope
- **Close to 0**: Graceful degradation (robust)
- **-0.5 to -1.0**: Moderate sensitivity
- **< -1.0**: Rapid failure cascade (vulnerable)

### Module Failure Frequency
- **High Vision failures**: Detection/segmentation issues
- **High Geometry failures**: Pose estimation problems
- **High Planning failures**: Path finding difficulties
- **High Control failures**: Trajectory tracking errors

### Root Causes
- **Occlusion**: Object blocking
- **Lighting**: Illumination variations
- **MotionBlur**: Camera/object motion
- **CameraJitter**: Camera instability
- **Overlap**: Multiple objects interfering

---

## ðŸ› Troubleshooting

### "ModuleNotFoundError: No module named 'pandas'"

Install dependencies:
```bash
pip install -r requirements.txt
```

### "Permission denied" when running bash script

Make executable:
```bash
chmod +x run_all.sh
```

### Tests failing

Check Python version (requires 3.10+):
```bash
python --version
```

### Out of memory

Reduce runs:
```bash
bash run_all.sh 1  # Use 1 run per level instead of 3
```

### Want to re-run specific scenario

Delete CSV and re-run:
```bash
rm results/occlusion_sweep.csv
bash run_all.sh
```

---

## ðŸ“š Additional Resources

- **Main README**: `README.md`
- **Original reproduce script**: `reproduce.sh` (single occlusion scenario)
- **Threshold config**: `configs/thresholds.yaml`
- **Perturbation config**: `configs/perturbations.yaml`
- **Test files**: `tests/`

---

## ðŸŽ‰ Summary

**One command. Complete automation. Comprehensive results.**

```bash
bash run_all.sh
```

Then open: `results/final_report/research_report.html`

**That's it!** The entire research pipeline runs automatically:
- âœ… No manual data downloading
- âœ… No manual experiment execution
- âœ… No manual analysis
- âœ… No manual visualization
- âœ… Comprehensive final report with discussion

**Perfect for:**
- ðŸ”¬ Reproducible research
- ðŸ“Š Systematic benchmarking
- ðŸŽ“ Educational demonstrations
- ðŸ­ Robustness testing

---

**Questions or issues?** Check the troubleshooting section above or examine individual scripts for detailed documentation.
